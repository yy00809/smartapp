{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [Root]",
      "language": "python",
      "name": "Python [Root]"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "name": "tensorflow.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlfX59KShm-2"
      },
      "source": [
        "## A very simple Tensorflow Logistic Regression example.\n",
        "\n",
        "we will build a logistic regression model of some  (fake) graduate school admissions decisions.  The data consists csv file of a GRE exam score in the range 0 to 800, a grade point average in the range 0 to 4.0 and the rank of the student's undergrad institution in the range 4 to 1 (top).   The Admission Decision in binary.  \n",
        "\n",
        "There are six columns in the data.  Ignore column 0.  the GRE, GPA and school rank are in columns 1 through 3.  Column 4 is an admission decision that is only based on the rank of the school: only students with a rank 1 school get in and others not.    Column 5 contains a more interesting (but still silly) admission model where you get in if your GRE score is 800 or your rank is 1.   in the example below we use the former model.  It is easy for the system to learn it perfectly.\n",
        "\n",
        "The csv file is called dat.csv and it is here https://1drv.ms/u/s!AkRG9Zk_IOUag5IX1xzlv7rP9T5FFg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7G-q0An7hm-3"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import csv"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuZfr6-ehm-4",
        "outputId": "dd8dc741-55bc-4ed2-dc2d-df541cb6924a"
      },
      "source": [
        "sess = tf.compat.v1.InteractiveSession()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py:1761: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TST_vYZ2hm-4"
      },
      "source": [
        "train_datas = []\n",
        "train_labels = []\n",
        "test_datas = []\n",
        "test_labels = []\n",
        "i = 0\n",
        "scale = np.array([[0.01, 1.0, 1.0]])\n",
        "with open('dat.csv', 'rt',encoding='latin1') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        if i < 300:\n",
        "            train_datas.append([np.float32(x) for x in row[1:4]])\n",
        "            #print np.float(row[0])\n",
        "            train_labels.append([np.float32(row[4])])\n",
        "        else:\n",
        "            test_datas.append([np.float32(x) for x in row[1:4]])\n",
        "            test_labels.append([np.float(row[4])])\n",
        "        i +=1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaaHD5-6hm-5"
      },
      "source": [
        "test_data  = np.array(test_datas, dtype=np.float32)\n",
        "test_label = np.array(test_labels, dtype=np.float32)\n",
        "train_data  = np.array(train_datas, dtype=np.float32)\n",
        "train_label = np.array(train_labels, dtype=np.float32)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qlRMk3Bhm-6",
        "outputId": "5bfc3306-afe1-499b-d895-e71a29fbfa4a"
      },
      "source": [
        "test_data[0:20]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[640.  ,   3.3 ,   2.  ],\n",
              "       [660.  ,   3.6 ,   3.  ],\n",
              "       [400.  ,   3.15,   2.  ],\n",
              "       [680.  ,   3.98,   2.  ],\n",
              "       [220.  ,   2.83,   3.  ],\n",
              "       [580.  ,   3.46,   4.  ],\n",
              "       [540.  ,   3.17,   1.  ],\n",
              "       [580.  ,   3.51,   2.  ],\n",
              "       [540.  ,   3.13,   2.  ],\n",
              "       [440.  ,   2.98,   3.  ],\n",
              "       [560.  ,   4.  ,   3.  ],\n",
              "       [660.  ,   3.67,   2.  ],\n",
              "       [660.  ,   3.77,   3.  ],\n",
              "       [520.  ,   3.65,   4.  ],\n",
              "       [540.  ,   3.46,   4.  ],\n",
              "       [300.  ,   2.84,   2.  ],\n",
              "       [340.  ,   3.  ,   2.  ],\n",
              "       [780.  ,   3.63,   4.  ],\n",
              "       [480.  ,   3.71,   4.  ],\n",
              "       [540.  ,   3.28,   1.  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzha1fz0hm-7",
        "outputId": "6b8eb8c4-a5b3-4ca2-bf70-ddf167720262"
      },
      "source": [
        "train_label[0:20]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdtyDu9ihm-7"
      },
      "source": [
        "first define the placeholders and variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "p1Qw9FP9hm-8"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=(None,3)) \n",
        "y = tf.placeholder(tf.float32, shape =(None,1)) \n",
        "\n",
        "# Set model weights\n",
        "W = tf.Variable(tf.zeros([3, 1]))\n",
        "b = tf.Variable(tf.zeros([1]))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "cwqeUMbYhm-9"
      },
      "source": [
        "training_epochs = 400000\n",
        "batch_size = 100\n",
        "display_step = 1000"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rdeDFxXhm-9",
        "outputId": "37ffe117-b38b-4765-c06c-9cf4622ec3c5"
      },
      "source": [
        "pred = tf.sigmoid(tf.matmul(x, W) + b) # Softmax\n",
        "cost = tf.sqrt(tf.reduce_sum((y - pred)**2/batch_size))\n",
        "\n",
        "opt = tf.train.AdamOptimizer()\n",
        "optimizer = opt.minimize(cost)\n",
        "\n",
        "# Initializing the variables old version is initialize_all_variable.  New version\n",
        "# has global_variable_initializer.\n",
        "\n",
        "#init = tf.global_variables_initializer()\n",
        "init = tf.initialize_all_variables()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:tensorflow:==================================\n",
            "Object was never used (type <class 'tensorflow.python.framework.ops.Operation'>):\n",
            "<tf.Operation 'init' type=NoOp>\n",
            "If you want to mark it as used call its \"mark_used()\" method.\n",
            "It was originally created here:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2737, in run_cell\n",
            "    return result  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n",
            "    return False  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2902, in run_code\n",
            "    return outflag  File \"<ipython-input-9-cae55e6355ed>\", line 11, in <module>\n",
            "    init = tf.initialize_all_variables()  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n",
            "    error_in_function=error_in_function)\n",
            "==================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "I2YzRIqnhm--"
      },
      "source": [
        "def get_batch2(batch_size, x, y):\n",
        "    indices = np.random.choice(299, batch_size)\n",
        "    return x[indices], y[indices]\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JHAzfR_hm--",
        "outputId": "37c8d869-c554-490d-e45f-32c92abedb80"
      },
      "source": [
        "sess.run(init)\n",
        "# Training cycle\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0.\n",
        "    total_batch = int(len(train_data)/batch_size)\n",
        "    # Loop over all batches\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = get_batch2(batch_size, train_data, train_label)\n",
        "        # Fit training using batch data\n",
        "        _, c = sess.run([optimizer, cost], feed_dict={x:batch_xs,y:batch_ys})\n",
        "        # Compute average loss\n",
        "        avg_cost += c / total_batch\n",
        "    # Display logs per epoch step\n",
        "    if (epoch+1) % display_step == 0:\n",
        "        print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", str(avg_cost))\n",
        "\n",
        "print (\"Optimization Finished!\")\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1000 cost= 0.18152697881062824\n",
            "Epoch: 2000 cost= 0.09144687155882518\n",
            "Epoch: 3000 cost= 0.05307899788022041\n",
            "Epoch: 4000 cost= 0.03495782365401586\n",
            "Epoch: 5000 cost= 0.022571133449673653\n",
            "Epoch: 6000 cost= 0.014903961991270382\n",
            "Epoch: 7000 cost= 0.007473531334350506\n",
            "Epoch: 8000 cost= 0.007253767767300209\n",
            "Epoch: 9000 cost= 0.0034579667262732983\n",
            "Epoch: 10000 cost= 0.003720525186508894\n",
            "Epoch: 11000 cost= 0.0020092947330946727\n",
            "Epoch: 12000 cost= 0.002035311384436985\n",
            "Epoch: 13000 cost= 0.001351064866563926\n",
            "Epoch: 14000 cost= 0.0010260945030798516\n",
            "Epoch: 15000 cost= 0.0008902437014815707\n",
            "Epoch: 16000 cost= 0.00043464912838923436\n",
            "Epoch: 17000 cost= 0.00038921140367165213\n",
            "Epoch: 18000 cost= 0.0003619960625655949\n",
            "Epoch: 19000 cost= 0.0003599119615197802\n",
            "Epoch: 20000 cost= 0.0003100393902665625\n",
            "Epoch: 21000 cost= 0.00018372688646195456\n",
            "Epoch: 22000 cost= 8.39459122895884e-05\n",
            "Epoch: 23000 cost= 7.08555259431402e-05\n",
            "Epoch: 24000 cost= 0.00010595115357621882\n",
            "Epoch: 25000 cost= 3.6476314562605694e-05\n",
            "Epoch: 26000 cost= 4.1045652324100956e-05\n",
            "Epoch: 27000 cost= 3.875102993333712e-05\n",
            "Epoch: 28000 cost= 2.6480910795119904e-05\n",
            "Epoch: 29000 cost= 1.3893877621740103e-05\n",
            "Epoch: 30000 cost= 1.571727595243525e-05\n",
            "Epoch: 31000 cost= 9.74839197927698e-06\n",
            "Epoch: 32000 cost= 1.0099056453327648e-05\n",
            "Epoch: 33000 cost= 7.467367443799351e-06\n",
            "Epoch: 34000 cost= 6.666681808079981e-06\n",
            "Epoch: 35000 cost= 7.360288994580818e-06\n",
            "Epoch: 36000 cost= 4.487420710574952e-06\n",
            "Epoch: 37000 cost= 3.0284501614611754e-06\n",
            "Epoch: 38000 cost= 3.024658250675808e-06\n",
            "Epoch: 39000 cost= 2.219179293661e-06\n",
            "Epoch: 40000 cost= 1.16272171150437e-06\n",
            "Epoch: 41000 cost= 7.930870159119271e-07\n",
            "Epoch: 42000 cost= 9.653209834444474e-07\n",
            "Epoch: 43000 cost= 1.0340808292615595e-06\n",
            "Epoch: 44000 cost= 5.787003469019206e-07\n",
            "Epoch: 45000 cost= 7.515945791662184e-07\n",
            "Epoch: 46000 cost= 2.9850585766174237e-07\n",
            "Epoch: 47000 cost= 5.372323528263223e-07\n",
            "Epoch: 48000 cost= 4.296252977079954e-07\n",
            "Epoch: 49000 cost= 2.1314853881904128e-07\n",
            "Epoch: 50000 cost= 1.297538811210567e-07\n",
            "Epoch: 51000 cost= 1.9162419562235303e-07\n",
            "Epoch: 52000 cost= 1.3168851372332332e-07\n",
            "Epoch: 53000 cost= 1.5415370550423782e-07\n",
            "Epoch: 54000 cost= 8.420571617762107e-08\n",
            "Epoch: 55000 cost= 7.770023439472121e-08\n",
            "Epoch: 56000 cost= 4.430456831035674e-08\n",
            "Epoch: 57000 cost= 1.4287156939000548e-08\n",
            "Epoch: 58000 cost= 2.3941204574384756e-08\n",
            "Epoch: 59000 cost= 4.212138785912127e-08\n",
            "Epoch: 60000 cost= 3.3561402842015774e-08\n",
            "Epoch: 61000 cost= 3.258291532877896e-08\n",
            "Epoch: 62000 cost= 3.6309872442075175e-08\n",
            "Epoch: 63000 cost= 1.0089750590580593e-08\n",
            "Epoch: 64000 cost= 7.128276339566734e-09\n",
            "Epoch: 65000 cost= 2.8120020682346574e-08\n",
            "Epoch: 66000 cost= 1.3971878172943285e-08\n",
            "Epoch: 67000 cost= 2.148939951910715e-09\n",
            "Epoch: 68000 cost= 1.8659702227807884e-08\n",
            "Epoch: 69000 cost= 1.1500067860955218e-08\n",
            "Epoch: 70000 cost= 1.1563462483839734e-08\n",
            "Epoch: 71000 cost= 9.320212157604145e-09\n",
            "Epoch: 72000 cost= 4.9122313624157714e-09\n",
            "Epoch: 73000 cost= 8.621190761282094e-09\n",
            "Epoch: 74000 cost= 1.2538143671451487e-09\n",
            "Epoch: 75000 cost= 2.5598612859075347e-09\n",
            "Epoch: 76000 cost= 5.141322108788889e-09\n",
            "Epoch: 77000 cost= 5.351114958547972e-09\n",
            "Epoch: 78000 cost= 6.475184777254839e-09\n",
            "Epoch: 79000 cost= 1.3857334169031787e-09\n",
            "Epoch: 80000 cost= 6.386029853070834e-10\n",
            "Epoch: 81000 cost= 1.3110165545763646e-09\n",
            "Epoch: 82000 cost= 1.2130886387999123e-08\n",
            "Epoch: 83000 cost= 6.628039598647698e-10\n",
            "Epoch: 84000 cost= 6.137427797462772e-09\n",
            "Epoch: 85000 cost= 7.258924942613969e-10\n",
            "Epoch: 86000 cost= 6.365395599505774e-09\n",
            "Epoch: 87000 cost= 4.24425464218281e-09\n",
            "Epoch: 88000 cost= 5.89675327085833e-10\n",
            "Epoch: 89000 cost= 9.872723009488975e-10\n",
            "Epoch: 90000 cost= 1.3278165048961435e-09\n",
            "Epoch: 91000 cost= 1.3139986136205077e-09\n",
            "Epoch: 92000 cost= 5.795047589944128e-10\n",
            "Epoch: 93000 cost= 8.059103403142604e-09\n",
            "Epoch: 94000 cost= 5.417083911070838e-10\n",
            "Epoch: 95000 cost= 3.447967837170533e-10\n",
            "Epoch: 96000 cost= 4.301319578292606e-10\n",
            "Epoch: 97000 cost= 3.3633879015226853e-10\n",
            "Epoch: 98000 cost= 1.513202230185584e-09\n",
            "Epoch: 99000 cost= 3.3108431736946403e-10\n",
            "Epoch: 100000 cost= 4.162314844643097e-10\n",
            "Epoch: 101000 cost= 3.105733494453607e-10\n",
            "Epoch: 102000 cost= 3.394280689850149e-10\n",
            "Epoch: 103000 cost= 2.865089600752787e-10\n",
            "Epoch: 104000 cost= 5.209374043246839e-10\n",
            "Epoch: 105000 cost= 7.428340072686741e-10\n",
            "Epoch: 106000 cost= 9.814847823363948e-10\n",
            "Epoch: 107000 cost= 1.9576050502845274e-10\n",
            "Epoch: 108000 cost= 3.6959253250460716e-10\n",
            "Epoch: 109000 cost= 3.706400926913508e-10\n",
            "Epoch: 110000 cost= 5.237415316254138e-10\n",
            "Epoch: 111000 cost= 1.3747064597779968e-10\n",
            "Epoch: 112000 cost= 6.035787883384991e-09\n",
            "Epoch: 113000 cost= 7.998153681021414e-09\n",
            "Epoch: 114000 cost= 6.208036584798293e-10\n",
            "Epoch: 115000 cost= 1.3043444565171333e-10\n",
            "Epoch: 116000 cost= 4.75955589755254e-10\n",
            "Epoch: 117000 cost= 3.265393834957682e-10\n",
            "Epoch: 118000 cost= 2.530048022938066e-10\n",
            "Epoch: 119000 cost= 3.2042202224857874e-10\n",
            "Epoch: 120000 cost= 1.5181043921952408e-10\n",
            "Epoch: 121000 cost= 2.0856129786158323e-10\n",
            "Epoch: 122000 cost= 3.317744505052881e-10\n",
            "Epoch: 123000 cost= 7.077871807166977e-10\n",
            "Epoch: 124000 cost= 2.141014125249067e-10\n",
            "Epoch: 125000 cost= 9.089336922007973e-11\n",
            "Epoch: 126000 cost= 2.60025232827014e-10\n",
            "Epoch: 127000 cost= 3.694942546372815e-10\n",
            "Epoch: 128000 cost= 4.3876494104644337e-10\n",
            "Epoch: 129000 cost= 2.2482475140842933e-10\n",
            "Epoch: 130000 cost= 1.0407671021302653e-10\n",
            "Epoch: 131000 cost= 2.118730191291718e-09\n",
            "Epoch: 132000 cost= 1.3131992252872018e-10\n",
            "Epoch: 133000 cost= 8.829229014573059e-11\n",
            "Epoch: 134000 cost= 3.7922887052843635e-11\n",
            "Epoch: 135000 cost= 6.915278303691134e-11\n",
            "Epoch: 136000 cost= 8.455164824070863e-09\n",
            "Epoch: 137000 cost= 4.925745737220192e-10\n",
            "Epoch: 138000 cost= 2.43810441743116e-10\n",
            "Epoch: 139000 cost= 1.6350199897689305e-10\n",
            "Epoch: 140000 cost= 4.022501315833112e-09\n",
            "Epoch: 141000 cost= 6.215545902040394e-11\n",
            "Epoch: 142000 cost= 2.115127309409992e-10\n",
            "Epoch: 143000 cost= 1.1277586734840621e-10\n",
            "Epoch: 144000 cost= 2.4095358578761033e-10\n",
            "Epoch: 145000 cost= 6.099508976601756e-11\n",
            "Epoch: 146000 cost= 5.225094778145885e-11\n",
            "Epoch: 147000 cost= 3.997131976102298e-09\n",
            "Epoch: 148000 cost= 8.065594581108115e-10\n",
            "Epoch: 149000 cost= 1.388482454012241e-10\n",
            "Epoch: 150000 cost= 5.986755304461985e-11\n",
            "Epoch: 151000 cost= 6.380711584097476e-11\n",
            "Epoch: 152000 cost= 4.664266658090573e-11\n",
            "Epoch: 153000 cost= 1.4055554636849266e-10\n",
            "Epoch: 154000 cost= 4.149949365631992e-11\n",
            "Epoch: 155000 cost= 3.652037237437492e-10\n",
            "Epoch: 156000 cost= 4.672880832279347e-11\n",
            "Epoch: 157000 cost= 7.421199650174219e-11\n",
            "Epoch: 158000 cost= 3.6479021655229837e-10\n",
            "Epoch: 159000 cost= 4.1280793020015416e-11\n",
            "Epoch: 160000 cost= 3.0996773435025084e-11\n",
            "Epoch: 161000 cost= 9.731349522497841e-11\n",
            "Epoch: 162000 cost= 3.2016362506761174e-11\n",
            "Epoch: 163000 cost= 2.3701139661991277e-10\n",
            "Epoch: 164000 cost= 3.0692759676413196e-11\n",
            "Epoch: 165000 cost= 2.3571175104356947e-11\n",
            "Epoch: 166000 cost= 1.3907858661029357e-10\n",
            "Epoch: 167000 cost= 1.755247151328613e-10\n",
            "Epoch: 168000 cost= 3.648958912805256e-11\n",
            "Epoch: 169000 cost= 6.788833615637793e-11\n",
            "Epoch: 170000 cost= 3.2100435735464096e-11\n",
            "Epoch: 171000 cost= 3.9808836782562196e-11\n",
            "Epoch: 172000 cost= 4.001705914552511e-09\n",
            "Epoch: 173000 cost= 4.607484648440815e-11\n",
            "Epoch: 174000 cost= 2.2924709353056016e-10\n",
            "Epoch: 175000 cost= 2.6992584093813818e-11\n",
            "Epoch: 176000 cost= 3.385314713740447e-11\n",
            "Epoch: 177000 cost= 1.2180955087185788e-10\n",
            "Epoch: 178000 cost= 2.6196537994405134e-11\n",
            "Epoch: 179000 cost= 2.7569580299258156e-11\n",
            "Epoch: 180000 cost= 2.1116633326193995e-11\n",
            "Epoch: 181000 cost= 3.40943511848805e-11\n",
            "Epoch: 182000 cost= 1.0647952658482396e-10\n",
            "Epoch: 183000 cost= 1.194553628467802e-11\n",
            "Epoch: 184000 cost= 1.0764498366751716e-09\n",
            "Epoch: 185000 cost= 2.4399475495595627e-11\n",
            "Epoch: 186000 cost= 4.1271015308967185e-10\n",
            "Epoch: 187000 cost= 4.6696853559883663e-11\n",
            "Epoch: 188000 cost= 1.8924530923817667e-11\n",
            "Epoch: 189000 cost= 1.3020268890828746e-10\n",
            "Epoch: 190000 cost= 2.0460307637952074e-11\n",
            "Epoch: 191000 cost= 1.0030278690953409e-10\n",
            "Epoch: 192000 cost= 3.4579096530595876e-11\n",
            "Epoch: 193000 cost= 1.982567466677724e-11\n",
            "Epoch: 194000 cost= 2.408428826742674e-10\n",
            "Epoch: 195000 cost= 9.364116079768614e-11\n",
            "Epoch: 196000 cost= 9.311850179827276e-10\n",
            "Epoch: 197000 cost= 2.200678111963228e-10\n",
            "Epoch: 198000 cost= 2.745812648433099e-11\n",
            "Epoch: 199000 cost= 3.659655044285781e-11\n",
            "Epoch: 200000 cost= 2.4387500410320375e-11\n",
            "Epoch: 201000 cost= 2.810531298432413e-10\n",
            "Epoch: 202000 cost= 1.5047138592997705e-11\n",
            "Epoch: 203000 cost= 1.4563203363145614e-11\n",
            "Epoch: 204000 cost= 1.2555359963500878e-11\n",
            "Epoch: 205000 cost= 1.5700188834196403e-11\n",
            "Epoch: 206000 cost= 1.2450745295877752e-11\n",
            "Epoch: 207000 cost= 1.506447252821082e-11\n",
            "Epoch: 208000 cost= 1.6599331573626437e-11\n",
            "Epoch: 209000 cost= 2.0720787585748468e-10\n",
            "Epoch: 210000 cost= 1.2258869845164593e-11\n",
            "Epoch: 211000 cost= 4.746238124742064e-11\n",
            "Epoch: 212000 cost= 1.3161833602171047e-11\n",
            "Epoch: 213000 cost= 1.069725066628798e-11\n",
            "Epoch: 214000 cost= 3.504772051280784e-11\n",
            "Epoch: 215000 cost= 1.7343409116262382e-11\n",
            "Epoch: 216000 cost= 1.708587871879219e-11\n",
            "Epoch: 217000 cost= 1.5300122742830286e-10\n",
            "Epoch: 218000 cost= 3.990019641654056e-09\n",
            "Epoch: 219000 cost= 2.517034613143861e-11\n",
            "Epoch: 220000 cost= 1.4954452606796842e-11\n",
            "Epoch: 221000 cost= 1.3940814648505384e-11\n",
            "Epoch: 222000 cost= 2.029902923990819e-11\n",
            "Epoch: 223000 cost= 8.796116844160078e-11\n",
            "Epoch: 224000 cost= 3.8433406919965066e-11\n",
            "Epoch: 225000 cost= 1.6284936362372566e-11\n",
            "Epoch: 226000 cost= 2.9990428832467795e-11\n",
            "Epoch: 227000 cost= 1.4725628679398048e-09\n",
            "Epoch: 228000 cost= 1.1274636317152678e-11\n",
            "Epoch: 229000 cost= 1.2458596365209445e-11\n",
            "Epoch: 230000 cost= 1.123701970593786e-11\n",
            "Epoch: 231000 cost= 1.237624181379034e-11\n",
            "Epoch: 232000 cost= 1.0114756254786528e-11\n",
            "Epoch: 233000 cost= 1.09822611074617e-11\n",
            "Epoch: 234000 cost= 1.533519376299234e-11\n",
            "Epoch: 235000 cost= 1.1905116475974253e-10\n",
            "Epoch: 236000 cost= 1.111585794475826e-11\n",
            "Epoch: 237000 cost= 1.825233135928824e-11\n",
            "Epoch: 238000 cost= 2.432309504270721e-11\n",
            "Epoch: 239000 cost= 4.1342156550013457e-11\n",
            "Epoch: 240000 cost= 1.2969604846109947e-11\n",
            "Epoch: 241000 cost= 1.816556511694915e-11\n",
            "Epoch: 242000 cost= 2.316527351886588e-11\n",
            "Epoch: 243000 cost= 1.3947045486110513e-11\n",
            "Epoch: 244000 cost= 7.79344378383969e-11\n",
            "Epoch: 245000 cost= 2.5567345116050966e-11\n",
            "Epoch: 246000 cost= 6.568177252086471e-11\n",
            "Epoch: 247000 cost= 6.2626654441048455e-12\n",
            "Epoch: 248000 cost= 6.819682665804017e-11\n",
            "Epoch: 249000 cost= 1.185005883928373e-11\n",
            "Epoch: 250000 cost= 1.0876937949858926e-11\n",
            "Epoch: 251000 cost= 3.657822054507302e-10\n",
            "Epoch: 252000 cost= 1.9331540072424028e-10\n",
            "Epoch: 253000 cost= 5.867674170619472e-11\n",
            "Epoch: 254000 cost= 1.613206414517269e-11\n",
            "Epoch: 255000 cost= 2.414828753627418e-10\n",
            "Epoch: 256000 cost= 7.94025001998877e-12\n",
            "Epoch: 257000 cost= 6.770047115504478e-10\n",
            "Epoch: 258000 cost= 9.066089748146119e-12\n",
            "Epoch: 259000 cost= 6.28077964348143e-12\n",
            "Epoch: 260000 cost= 1.0995483458916173e-11\n",
            "Epoch: 261000 cost= 7.355529380026482e-12\n",
            "Epoch: 262000 cost= 6.589150666064247e-12\n",
            "Epoch: 263000 cost= 1.5280663771359096e-10\n",
            "Epoch: 264000 cost= 7.040960551864723e-12\n",
            "Epoch: 265000 cost= 6.4553985710165875e-12\n",
            "Epoch: 266000 cost= 9.114888676007665e-12\n",
            "Epoch: 267000 cost= 1.5943382725147615e-10\n",
            "Epoch: 268000 cost= 3.590430383559884e-11\n",
            "Epoch: 269000 cost= 1.028139379188886e-10\n",
            "Epoch: 270000 cost= 4.799874762697239e-12\n",
            "Epoch: 271000 cost= 7.951190012534895e-09\n",
            "Epoch: 272000 cost= 8.952613245645964e-12\n",
            "Epoch: 273000 cost= 4.030908650846469e-11\n",
            "Epoch: 274000 cost= 8.105930857094101e-12\n",
            "Epoch: 275000 cost= 1.4632830537542052e-11\n",
            "Epoch: 276000 cost= 1.1271355955059608e-11\n",
            "Epoch: 277000 cost= 5.9847761873603e-12\n",
            "Epoch: 278000 cost= 5.9272630206774765e-12\n",
            "Epoch: 279000 cost= 8.80193082771393e-12\n",
            "Epoch: 280000 cost= 1.6667124162298802e-10\n",
            "Epoch: 281000 cost= 9.034608362360844e-11\n",
            "Epoch: 282000 cost= 4.1417654896014344e-12\n",
            "Epoch: 283000 cost= 1.0548713812175148e-11\n",
            "Epoch: 284000 cost= 7.60721057905626e-12\n",
            "Epoch: 285000 cost= 9.276072820742682e-12\n",
            "Epoch: 286000 cost= 6.16423544153033e-11\n",
            "Epoch: 287000 cost= 1.626143577432293e-11\n",
            "Epoch: 288000 cost= 6.189916923933966e-12\n",
            "Epoch: 289000 cost= 1.1985243960482839e-11\n",
            "Epoch: 290000 cost= 8.115390737889472e-12\n",
            "Epoch: 291000 cost= 8.577817391571449e-11\n",
            "Epoch: 292000 cost= 7.147931841329965e-12\n",
            "Epoch: 293000 cost= 6.460772599784874e-12\n",
            "Epoch: 294000 cost= 1.3074172242518351e-11\n",
            "Epoch: 295000 cost= 1.2999478229969164e-11\n",
            "Epoch: 296000 cost= 4.761296500295498e-12\n",
            "Epoch: 297000 cost= 8.133092579039788e-12\n",
            "Epoch: 298000 cost= 7.1682908451646075e-12\n",
            "Epoch: 299000 cost= 3.2273185859854614e-11\n",
            "Epoch: 300000 cost= 8.081761244023895e-12\n",
            "Epoch: 301000 cost= 8.381082503353121e-12\n",
            "Epoch: 302000 cost= 5.244132240724472e-12\n",
            "Epoch: 303000 cost= 5.9385735623011336e-12\n",
            "Epoch: 304000 cost= 2.370322283358946e-11\n",
            "Epoch: 305000 cost= 8.36925768849898e-12\n",
            "Epoch: 306000 cost= 2.2456160773491145e-11\n",
            "Epoch: 307000 cost= 2.3447404203421246e-10\n",
            "Epoch: 308000 cost= 2.6849965537959857e-11\n",
            "Epoch: 309000 cost= 4.632531482260763e-12\n",
            "Epoch: 310000 cost= 6.781532511472104e-12\n",
            "Epoch: 311000 cost= 7.570792372642761e-11\n",
            "Epoch: 312000 cost= 7.610309084304934e-12\n",
            "Epoch: 313000 cost= 3.5814869588553693e-12\n",
            "Epoch: 314000 cost= 6.0782938289076026e-12\n",
            "Epoch: 315000 cost= 1.066123689330567e-09\n",
            "Epoch: 316000 cost= 4.745984276873413e-12\n",
            "Epoch: 317000 cost= 2.921788209234629e-12\n",
            "Epoch: 318000 cost= 1.353772233203543e-10\n",
            "Epoch: 319000 cost= 8.018148211358378e-12\n",
            "Epoch: 320000 cost= 9.89989774186073e-12\n",
            "Epoch: 321000 cost= 8.195855163521207e-12\n",
            "Epoch: 322000 cost= 3.977022720623331e-09\n",
            "Epoch: 323000 cost= 8.818338420590877e-12\n",
            "Epoch: 324000 cost= 5.4673456155914426e-12\n",
            "Epoch: 325000 cost= 5.078184545324419e-12\n",
            "Epoch: 326000 cost= 5.888326718578307e-12\n",
            "Epoch: 327000 cost= 3.595933446842725e-12\n",
            "Epoch: 328000 cost= 1.0542082687127937e-11\n",
            "Epoch: 329000 cost= 8.696674746085561e-12\n",
            "Epoch: 330000 cost= 3.111804193952258e-10\n",
            "Epoch: 331000 cost= 5.9630168279996755e-12\n",
            "Epoch: 332000 cost= 1.568152696816242e-11\n",
            "Epoch: 333000 cost= 5.346285191174896e-12\n",
            "Epoch: 334000 cost= 4.955572844439482e-12\n",
            "Epoch: 335000 cost= 5.888478940563324e-12\n",
            "Epoch: 336000 cost= 9.908636122250384e-12\n",
            "Epoch: 337000 cost= 1.1694853419008666e-11\n",
            "Epoch: 338000 cost= 3.766534537967084e-12\n",
            "Epoch: 339000 cost= 5.804823346537239e-12\n",
            "Epoch: 340000 cost= 6.089634149950932e-12\n",
            "Epoch: 341000 cost= 6.763362439543564e-12\n",
            "Epoch: 342000 cost= 1.8391541761753064e-11\n",
            "Epoch: 343000 cost= 4.6084371735366503e-10\n",
            "Epoch: 344000 cost= 5.564257388179783e-12\n",
            "Epoch: 345000 cost= 6.621780438790618e-11\n",
            "Epoch: 346000 cost= 6.290293517544991e-12\n",
            "Epoch: 347000 cost= 8.8890246436694e-12\n",
            "Epoch: 348000 cost= 3.844511297854125e-12\n",
            "Epoch: 349000 cost= 5.952642892492754e-12\n",
            "Epoch: 350000 cost= 1.100965412587085e-11\n",
            "Epoch: 351000 cost= 1.1817583023265854e-10\n",
            "Epoch: 352000 cost= 5.24263213859862e-12\n",
            "Epoch: 353000 cost= 1.037111354550609e-11\n",
            "Epoch: 354000 cost= 4.785707304980994e-11\n",
            "Epoch: 355000 cost= 4.128584048708935e-12\n",
            "Epoch: 356000 cost= 5.860217548494158e-12\n",
            "Epoch: 357000 cost= 5.45086256224329e-12\n",
            "Epoch: 358000 cost= 6.000033658572676e-12\n",
            "Epoch: 359000 cost= 6.304059560248894e-12\n",
            "Epoch: 360000 cost= 1.1172455177445768e-11\n",
            "Epoch: 361000 cost= 3.875370076927842e-12\n",
            "Epoch: 362000 cost= 4.34555752493182e-10\n",
            "Epoch: 363000 cost= 1.3147570127510406e-11\n",
            "Epoch: 364000 cost= 5.51636326317125e-12\n",
            "Epoch: 365000 cost= 8.7579351178609e-11\n",
            "Epoch: 366000 cost= 5.1675829414177255e-12\n",
            "Epoch: 367000 cost= 3.836594887271505e-12\n",
            "Epoch: 368000 cost= 7.156137517052205e-12\n",
            "Epoch: 369000 cost= 4.288914709493774e-12\n",
            "Epoch: 370000 cost= 3.7569963344067744e-11\n",
            "Epoch: 371000 cost= 8.758973581157736e-12\n",
            "Epoch: 372000 cost= 4.851680255463231e-12\n",
            "Epoch: 373000 cost= 5.169994785290492e-12\n",
            "Epoch: 374000 cost= 7.290789499903028e-12\n",
            "Epoch: 375000 cost= 1.5545574087264907e-10\n",
            "Epoch: 376000 cost= 4.571945252940246e-12\n",
            "Epoch: 377000 cost= 3.3330710876485386e-12\n",
            "Epoch: 378000 cost= 6.324631356829924e-12\n",
            "Epoch: 379000 cost= 1.9294341876511616e-11\n",
            "Epoch: 380000 cost= 8.558683131422901e-12\n",
            "Epoch: 381000 cost= 3.932954078152603e-12\n",
            "Epoch: 382000 cost= 3.9470457573650045e-11\n",
            "Epoch: 383000 cost= 4.693449766566641e-12\n",
            "Epoch: 384000 cost= 5.1834023907561715e-12\n",
            "Epoch: 385000 cost= 3.691833008282834e-12\n",
            "Epoch: 386000 cost= 3.4335000120844224e-12\n",
            "Epoch: 387000 cost= 4.7135946043321466e-12\n",
            "Epoch: 388000 cost= 1.4024783649239463e-11\n",
            "Epoch: 389000 cost= 7.764721013150028e-12\n",
            "Epoch: 390000 cost= 5.680430662883632e-12\n",
            "Epoch: 391000 cost= 4.6229994658808504e-12\n",
            "Epoch: 392000 cost= 6.754755898138083e-12\n",
            "Epoch: 393000 cost= 9.61963870828771e-12\n",
            "Epoch: 394000 cost= 3.6062389330524893e-12\n",
            "Epoch: 395000 cost= 4.346648547458772e-12\n",
            "Epoch: 396000 cost= 6.551982769988548e-12\n",
            "Epoch: 397000 cost= 3.79148043979279e-12\n",
            "Epoch: 398000 cost= 2.1025764925427143e-10\n",
            "Epoch: 399000 cost= 5.784723972982834e-12\n",
            "Epoch: 400000 cost= 3.6268192586906096e-12\n",
            "Optimization Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhXqUernhm-_"
      },
      "source": [
        "define a function in python to compute sigmoid of an array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "OkZmoIAUhm_A"
      },
      "source": [
        "def sigmoida(z):\n",
        "    res = np.zeros(len(z))\n",
        "    for i in range(len(z)):\n",
        "        y = 1.0/(1.0+np.exp(-z[i]))\n",
        "        if y > 0.5:\n",
        "            res[i] = 1\n",
        "        else:\n",
        "            res[i] = 0\n",
        "    return res"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "084O30lchm_A"
      },
      "source": [
        "p = sigmoida(pred.eval({x:test_data}))\n",
        "q = y.eval({y:test_label})"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2Nde1Obhm_B"
      },
      "source": [
        "how accurate is this. In other words whaat fraction of the cases have p = q.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhbCMloAhm_C"
      },
      "source": [
        "def accurate(p,q):\n",
        "    total = 0.0\n",
        "    numones = 0.\n",
        "    numzeros = 0.\n",
        "    for i in range(len(p)):\n",
        "        if p[i] == 0:\n",
        "            numzeros += 1\n",
        "        else:\n",
        "            numones += 1\n",
        "        if p[i] == q[i]:\n",
        "            total +=1\n",
        "    print (\"accuracy = \"+str(total/len(p)))\n",
        "    print ('ratio of 1s ='+str(numones/len(p)))\n",
        "    print ('ratio of 0s ='+str(numzeros/len(p)))\n",
        "    \n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoP81XvMhm_C",
        "outputId": "d929dc2e-2b5a-4e1c-d628-f5e7a8615f67"
      },
      "source": [
        "accurate(p,q)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy = 1.0\n",
            "ratio of 1s =0.16\n",
            "ratio of 0s =0.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mtsRfUlShm_D"
      },
      "source": [
        "def softmax(v):\n",
        "    k = len(v)\n",
        "    res = np.zeros(k)\n",
        "    tot = 0.0\n",
        "    for i in range(k):\n",
        "        res[i] = np.exp(v[i])\n",
        "        tot += res[i]\n",
        "    for i in range(k):\n",
        "        res[i] = res[i]/tot\n",
        "    return res"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NIkosQDPhm_D"
      },
      "source": [
        "def sigmoid(x):\n",
        "    y = 1.0/(1.0+np.exp(-x))\n",
        "    if y > 0.5:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaoAEGbihm_E"
      },
      "source": [
        "if we wish, we may look at the trained W and b arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e00OGhzDhm_F"
      },
      "source": [
        "w =W.eval()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1zOGFKShm_F",
        "outputId": "c3a18dab-ad03-45f5-e3fb-06f29278d435"
      },
      "source": [
        "w"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.9985535e-03],\n",
              "       [ 4.8968406e+00],\n",
              "       [-4.8550087e+01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLRU7JL3hm_G"
      },
      "source": [
        "lb =b.eval()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pMyoXEjhm_G",
        "outputId": "855e93b2-0417-49e4-c33c-5497ed1df74a"
      },
      "source": [
        "lb"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([49.485455], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6Gcmellhm_H",
        "outputId": "6626bad2-1ae4-4f84-a898-6650d3b425a7"
      },
      "source": [
        "for i in range(20):\n",
        "    print (sigmoid(np.matmul(train_data[i], w)+lb))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "pjjuckqchm_I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "agfq84QXhm_I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Tj4cRTOnhm_I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}